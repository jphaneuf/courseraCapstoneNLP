---
title: "Coursera/JHU NLP Milestone Report"
output: html_document
date: "December 16, 2015"
---
```{r message=FALSE,cache=FALSE}
library(tm)
library(quanteda)
library(RWeka)
library(wordcloud)
library(stringr)
#library(qdap)
source('./nlpCustomFunctions.R')
enDir <- './final/en_US' #full dataset
enDir <- './finalsub/en_US' #subset dataset, see appendix for BASH
```

```{r}
ec <- VCorpus(DirSource(enDir))#english corpus
ec <- cleanupFun(ec)
options(mc.cores=1)
```

```{r}
createDTMxGrams <- function(n){
  #Create DTM on corpus for n-gram
  NGramTokenizerC <- function(x) NGramTokenizer(x,Weka_control(min=n,max=n)) 
  grams <- tm_map(ec,NGramTokenizerC)
  grams <- tm_map(grams,function(x) gsub(' ','_',x))#term document separates on whitespace
  grams <- tm_map(grams,PlainTextDocument)
  dtm <- TermDocumentMatrix(grams)
  dtm <- as.matrix(dtm)
  dtm <- cbind(dtm,rowSums(dtm))
  dtm <- cbind(dtm,rep(n,nrow(dtm)))
  colnames(dtm) <- c('news','blogs','twitter','total','n')
  dtm <- dtm[order(dtm[,'total'],decreasing=TRUE),]
  dtm
}
unigrams <- createDTMxGrams(1)
write.csv(unigrams,file='unigrams.csv')
bigrams <- createDTMxGrams(2)
write.csv(bigrams,file='bigrams.csv')
trigrams <- createDTMxGrams(3)
write.csv(trigrams,file='trigrams.csv')
quadgrams <- createDTMxGrams(4)
write.csv(quadgrams,file='quadgrams.csv')
```
```{r}
unigrams <- as.matrix(read.csv('unigrams.csv',row.names=1))
bigrams <- as.matrix(read.csv('bigrams.csv',row.names=1))
trigrams <- as.matrix(read.csv('trigrams.csv',row.names=1))
quadgrams <- as.matrix(read.csv('quadgrams.csv',row.names=1))
```
```{r}

```

```{r}
predict <- function(userInput){
  userInput <- tolower(userInput)
  userInput <- gsub(' ','_',userInput)
  #search
  #index <- head(grep(userInput,rownames(b)),n=1)
  index <- head(grep(userInput,rownames(quadgrams)),n=1)
  if(length(index)){
    return(rownames(quadgrams)[index])
  }else{
    return(userInput)
  }
}
```

 

