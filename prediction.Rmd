---
title: "Coursera/JHU NLP Milestone Report"
output: html_document
date: "December 16, 2015"
---
```{r message=FALSE,cache=FALSE}
library(tm)
library(quanteda)
library(RWeka)
library(wordcloud)
library(stringr)
#library(qdap)
source('./nlpCustomFunctions.R')
enDir <- './final/en_US' #full dataset
enDir <- './finalsub/en_US' #subset dataset, see appendix for BASH
```

```{r}
ec <- VCorpus(DirSource(enDir))#english corpus
ec <- cleanupFun(ec)
options(mc.cores=1)
```

```{r}
createDTMxGrams <- function(n){
  #Create DTM on corpus for n-gram
  NGramTokenizerC <- function(x) NGramTokenizer(x,Weka_control(min=n,max=n)) 
  grams <- tm_map(ec,NGramTokenizerC)
  grams <- tm_map(grams,function(x) gsub(' ','_',x))#term document separates on whitespace
  grams <- tm_map(grams,PlainTextDocument)
  dtm <- TermDocumentMatrix(grams)
  dtm <- as.matrix(dtm)
  dtm <- cbind(dtm,rowSums(dtm))
  dtm <- cbind(dtm,rep(n,nrow(dtm)))
  colnames(dtm) <- c('news','blogs','twitter','total','n')
  dtm <- dtm[order(dtm[,'total'],decreasing=TRUE),]
  dtm
}
unigrams <- createDTMxGrams(1)
write.csv(unigrams,file='unigrams.csv')
bigrams <- createDTMxGrams(2)
write.csv(bigrams,file='bigrams.csv')
trigrams <- createDTMxGrams(3)
write.csv(trigrams,file='trigrams.csv')
quadgrams <- createDTMxGrams(4)
write.csv(quadgrams,file='quadrams.csv')
```

```{r}
predict <- function(userInput){
  #clean
  #add underscores
  #search

  #return userInput if no match
}
#convert to matrix
#sort
```

 

